# Compiler Design Project – README

## Overview

This repository contains the implementation of a four-phase compiler project for a hypothetical programming language called **Trust**, inspired by the Rust programming language. Each phase of the project has its dedicated code and builds upon the previous one. The accompanying document `Project_Info.pdf` provides detailed descriptions of the implementation steps and design decisions. However, for the sake of clarity and ease of understanding, this README includes a summarized yet comprehensive walkthrough of the project deliverables and behaviors in each phase.

> Due to the limited timeframe allocated for this project, not all features described in the documentation are fully implemented. Some parts may contain bugs or incomplete sections. However, we assure you that all key concepts are demonstrated properly, and each phase showcases meaningful output that reflects the core function of a compiler component — especially helpful if you are a Computer Engineering student encountering compilers for the first time.

---

## Phase 1 – Lexical Analyzer

In this phase, we implemented the **Lexical Analyzer** for the Trust language. This component takes the raw program input and scans it to extract meaningful **tokens** such as keywords, identifiers, literals, and punctuation symbols.

The analyzer gives higher priority to reserved keywords, ensuring correct token recognition before checking for general identifiers. At this stage, the structure of the code is **not** verified — only tokenization is performed and passed on to the next phase: **Syntax Analysis**.

> The lexical analyzer is complete and fully functional.  
> Input files must be placed as `test.trust` in the same directory level as the `src` and `out` folders.  
> You can locate and change the file read path using `ctrl + f` and searching for `path` in the source code.

### Sample Input Code
```trust
let x = 10;
fn greet() {
    println!("Hello World!");
}
let y = 0x1F;
```

### Sample Output Tokens
```text
Line 1: <T_Let, let>
Line 1: <T_Id, x>
Line 1: <T_Assign, =>
Line 1: <T_Decimal, 10>
Line 1: <T_Semicolon, ;>
Line 2: <T_Fn, fn>
Line 2: <T_Id, greet>
Line 2: <T_LP, (>
Line 2: <T_RP, )>
Line 2: <T_LC, {>
Line 3: <T_Print, println!>
Line 3: <T_LP, (>
Line 3: <T_String, "Hello World!">
Line 3: <T_RP, )>
Line 3: <T_Semicolon, ;>
Line 4: <T_RC, }>
Line 5: <T_Let, let>
Line 5: <T_Id, y>
Line 5: <T_Assign, =>
Line 5: <T_Hexadecimal, 0x1F>
Line 5: <T_Semicolon, ;>

Process finished with exit code 0
```

---

## Phase 2 – Syntax Analyzer

In Phase 2, we implemented the **Syntax Analyzer** (also known as the Parser) which receives the token sequence generated by the lexical analyzer and checks for syntactical correctness. If the input is syntactically valid, the parser constructs and prints a **parse tree** representing the program's structure. Otherwise, it reports detailed syntax errors.

The parser adheres to a simplified LL(1)-style grammar customized for the Trust language and demonstrates how abstract syntax tree (AST) generation is achieved from a valid token stream.

### Sample Parse Tree Output for the Previous Input
```text
|-- program
    ||-- let
    |   ||-- T_Let: 'let'
    |   ||-- T_Id: 'x'
    |   ||-- T_Decimal: '10'
    |   |-- T_Semicolon: ';'
    ||-- function
    |   ||-- T_Fn: 'fn'
    |   ||-- T_Id: 'greet'
    |   ||-- T_LP: '('
    |   ||-- params
    |   ||-- T_RP: ')'
    |   ||-- T_LC: '{'
    |   ||-- block
    |   |   |-- println
    |   |       ||-- T_Print: 'println!'
    |   |       ||-- T_LP: '('
    |   |       ||-- T_String: '"Hello World!"'
    |   |       ||-- T_RP: ')'
    |   |       |-- T_Semicolon: ';'
    |   |-- T_RC: '}'
    |-- let
        ||-- T_Let: 'let'
        ||-- T_Id: 'y'
        ||-- T_Hexadecimal: '0x1F'
        |-- T_Semicolon: ';'

Process finished with exit code 0
```

---
